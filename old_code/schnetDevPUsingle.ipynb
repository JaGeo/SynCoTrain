{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set up for using Schnet on our crystal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 18 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path  #recommended path library for python3\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import schnetpack as spk\n",
    "from schnetpack.data import ASEAtomsData, BaseAtomsData, AtomsDataFormat, AtomsDataModule\n",
    "import schnetpack.transform as trn\n",
    "import torch\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import schnet4class\n",
    "# from pymatgen.io.ase import AseAtomsAdaptor as pase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/samariam/projects/chemheuristics\n",
      "/home/samariam/projects/chemheuristics\n"
     ]
    }
   ],
   "source": [
    "print(Path().resolve())  #current working directory\n",
    "print(Path().absolute()) #file path in jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Important note!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm gonna use electron volt for the compulsory unit decleration to see if I can complete the classification workflow. But even if it works I'll need to fix it soon. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'll try doing a regression and getting the round number (or closest number to label) as the class. Later I'll have to use classiification loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'split.npz'\n",
      "[Errno 2] No such file or directory: 'qm9tut/lightning_logs/best_inference_model'\n"
     ]
    }
   ],
   "source": [
    "qm9tut = './qm9tut/lightning_logs'\n",
    "if not os.path.exists('qm9tut/lightning_logs'):\n",
    "    os.makedirs(qm9tut)\n",
    "    \n",
    "splitFile_path = Path('split.npz')\n",
    "# splitFile_path = 'split.npz'\n",
    "\n",
    "try:\n",
    "    splitFile_path.unlink()\n",
    "except OSError as e:\n",
    "    print(e)\n",
    "    splitFile_path = Path(qm9tut+'/'+str(splitFile_path))\n",
    "    try:\n",
    "        splitFile_path.unlink()\n",
    "    except OSError as e:\n",
    "        print(e)\n",
    "        \n",
    "datapath = Path('./class_dataset.db')\n",
    "try:\n",
    "    datapath.unlink()\n",
    "except OSError as e:\n",
    "    print(e)        \n",
    "    \n",
    "bestModel_path = Path(qm9tut+'/best_inference_model')\n",
    "try:\n",
    "    bestModel_path.unlink()\n",
    "except OSError as e:\n",
    "    print(e)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try using the best_model to predict as the example. Just figure out the least amount of test data you can provide to the trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cpu')     #gpu was busy\n",
    "# torch.device('cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pAtoms = np.load(\"data_for_dev_try/PosAtomsUnder12.npy\", allow_pickle=True)\n",
    "tAtoms = np.load(\"data_for_dev_try/TheoAtomsUnder12.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of positive data is 1170 and the length of the theoretical data is 2752\n"
     ]
    }
   ],
   "source": [
    "print('The length of positive data is {} and the length of the theoretical data is {}'.format(len(pAtoms), len(tAtoms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "np.random.shuffle(pAtoms)\n",
    "np.random.shuffle(tAtoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypAtoms = pAtoms[:100]\n",
    "testpAtoms = pAtoms[-20:]\n",
    "mytAtoms = tAtoms[:500]\n",
    "testtAtoms = tAtoms[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.int32?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pSynth = [np.array(1).flatten()]*len(mypAtoms)    #we need the array to have the shape (1,), hence we use flatten()\n",
    "# tSynth = [np.array(0).flatten()]*len(mytAtoms)\n",
    "\n",
    "# changed int64 to float32, didn't help the float dataset.\n",
    "# pSynth = [np.array([1.], dtype=np.float32)[0].flatten()]*len(mypAtoms)    #we need the array to have the shape (1,), hence we use flatten()\n",
    "# tSynth = [np.array([1.], dtype=np.float32)[0].flatten()]*len(mytAtoms)\n",
    "\n",
    "pSynth = [np.array(1, dtype=np.int32).flatten()]*len(mypAtoms)    #we need the array to have the shape (1,), hence we use flatten()\n",
    "tSynth = [np.array(0, dtype=np.int32).flatten()]*len(mytAtoms)\n",
    "\n",
    "testpSynth = [np.array(1, dtype=np.int32).flatten()]*len(testpAtoms)    #here we prepare test data in the same format as the  training data.\n",
    "testtSynth = [np.array(0, dtype=np.int32).flatten()]*len(testtAtoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1], dtype=int32), (1,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pSynth[0], pSynth[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "crysData = np.concatenate([mypAtoms, mytAtoms])\n",
    "testCrysData = np.concatenate([testpAtoms, testtAtoms])\n",
    "\n",
    "targetData = [*pSynth, *tSynth]   #again, we need distinct arrays. np.concatenate would merge all in one array.\n",
    "testTargetData = [*testpSynth, *testtSynth]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "crysdf = pd.DataFrame()\n",
    "testCrysdf = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "crysdf['myatoms'] = crysData\n",
    "testCrysdf['myatoms'] = testCrysData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "crysdf['targets'] = targetData\n",
    "testCrysdf['targets'] = testTargetData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,) (1,)\n"
     ]
    }
   ],
   "source": [
    "print(targetData[0].shape, testTargetData[0].shape)      #each shape needs to be (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "crysdf.targets = crysdf.targets.map(lambda crystalClass: dict(synth=np.array(crystalClass)) )     #changes targets fromat from array to dict with array val\n",
    "testCrysdf.targets = testCrysdf.targets.map(lambda crystalClass: dict(synth=np.array(crystalClass)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'synth': array([1], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "print(crysdf.loc[0].targets)\n",
    "# this needs to return {'synth':array([1 or 0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to shuffle here to mix the positive and unlabaled data together.\n",
    "crysdf = crysdf.sample(frac=1, random_state=1).reset_index(drop=True)     #simply shuffles the rows of the dataframe\n",
    "testCrysdf = testCrysdf.sample(frac=1, random_state=1).reset_index(drop=True)     #simply shuffles the rows of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The #training data is 478, #validation data 118 and #internal test data 4. \n"
     ]
    }
   ],
   "source": [
    "# %rm split.npz\n",
    "# %rm qm9tut/lightning_logs/split.npz\n",
    "\n",
    "trainLength = round(len(crysdf)*.8)-2\n",
    "# valLength = round(trainLength*.2)-2\n",
    "valLength = round(len(crysdf)*.2)-2\n",
    "testLength = len(crysdf)-(trainLength+valLength)\n",
    "\n",
    "print('The #training data is {}, #validation data {} and #internal test data {}. '.format(trainLength, valLength, testLength))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datapath = './class_dataset.db'\n",
    "# datapath = './class_dataset2.db'\n",
    "# %rm {datapath}\n",
    "# %rm qm9tut/lightning_logs/best_inference_model\n",
    "# %rm synth/lightning_logs/best_inference_model\n",
    "\n",
    "class_dataset = ASEAtomsData.create(str(datapath), \n",
    "                                  distance_unit='Ang',\n",
    "                                  property_unit_dict={'synth':int(1)}                                  \n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dataset.add_systems(np.array(crysdf.targets), np.array(crysdf.myatoms))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- synth\n",
      "\n",
      "Properties of molecule with id 0:\n",
      "- _idx : torch.Size([1])\n",
      "- synth : torch.Size([1])\n",
      "- _n_atoms : torch.Size([1])\n",
      "- _atomic_numbers : torch.Size([10])\n",
      "- _positions : torch.Size([10, 3])\n",
      "- _cell : torch.Size([1, 3, 3])\n",
      "- _pbc : torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for p in class_dataset.available_properties:\n",
    "    print('-', p)\n",
    "print()\n",
    "\n",
    "example = class_dataset[0]\n",
    "print('Properties of molecule with id 0:')\n",
    "\n",
    "for k, v in example.items():\n",
    "    print('-', k, ':', v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[ 'synth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop! \n",
    "# is the synth property above still integer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "crysData = AtomsDataModule(datapath=datapath,\n",
    "                   batch_size=20,\n",
    "                #    batch_size=100,\n",
    "    num_train=trainLength,\n",
    "    num_val=valLength,\n",
    "    transforms=[\n",
    "        trn.ASENeighborList(cutoff=5.),\n",
    "        # trn.RemoveOffsets('fepa', remove_mean=True, remove_atomrefs=True),\n",
    "        # trn.CastTo32()\n",
    "    ],\n",
    "    property_units={'synth':int(1)},\n",
    "    # property_units={'synth':'eV'},\n",
    "    # property_units={'synth':'arb. unit'},     #need to fix this\n",
    "    num_workers=1,\n",
    "    split_file=os.path.join(qm9tut, \"split.npz\"),\n",
    "    pin_memory=False, # set to false, when not using a GPU\n",
    "    # pin_memory=True, # set to false, when not using a GPU\n",
    "    load_properties=['synth'], #only load U0 property\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(crysData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "crysData.prepare_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "crysData.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crysData.train_dataset[0]['synth']\n",
    "# this is available only after we run prepare_data and setup. Probbaby changes somewhere there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total length of the data set is 600\n",
      "The length of the training set is 478\n",
      "The length of the validation set is 118\n",
      "The length of the test set is 4\n"
     ]
    }
   ],
   "source": [
    "print(\"The total length of the data set is\", len(class_dataset))\n",
    "print(\"The length of the training set is\", trainLength)\n",
    "print(\"The length of the validation set is\", valLength)\n",
    "print(\"The length of the test set is\", len(class_dataset)-(trainLength+valLength))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atomrefs = crysData.train_dataset.atomrefs\n",
    "# atomrefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'synth': array([0], dtype=int32)}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stop!\n",
    "crysdf.loc[0].targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crysData.dataset[0]['synth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:09<00:00,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean atomization energy / atom: 0.027122163654121897\n",
      "Std. dev. atomization energy / atom: 0.06723066669679122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "means, stddevs = crysData.get_stats(\n",
    "    'synth', divide_by_atoms=True, remove_atomref=True\n",
    "    # 'synth', divide_by_atoms=True, remove_atomref=True\n",
    ")\n",
    "print('Mean atomization energy / atom:', means.item())\n",
    "print('Std. dev. atomization energy / atom:', stddevs.item())\n",
    "# This doesn't work when no test data is given, and it has no docstring. Does it calculate the mean and and std of test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 5\n",
    "radial_basis = spk.nn.GaussianRBF(n_rbf=20, cutoff=cutoff)\n",
    "n_atom_basis = 30\n",
    "n_filters = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_distance = spk.atomistic.PairwiseDistances() # calculates pairwise distances between atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn import functional\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "schnet = spk.representation.SchNet(\n",
    "    n_atom_basis=n_atom_basis, n_filters=n_filters, n_interactions=3, radial_basis=radial_basis,\n",
    "    \n",
    "    cutoff_fn = spk.nn.CosineCutoff(cutoff), \n",
    "    # activation=functional.sigmoid   #this might change all the activations\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_synth = spk.atomistic.Atomwise(n_in=n_atom_basis, output_key='synth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnpot = spk.model.NeuralNetworkPotential(\n",
    "    representation=schnet,\n",
    "    input_modules=[pairwise_distance],\n",
    "    output_modules=[pred_synth], \n",
    "    postprocessors=[trn.CastTo64(), trn.AddOffsets('synth', add_mean=True, add_atomrefs=False)]  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_synth = spk.task.ModelOutput(\n",
    "#     name='synth',\n",
    "#     loss_fn=torch.nn.MSELoss(), #this+metrics below later changes to BCELoss \n",
    "#     loss_weight=1.,\n",
    "#     metrics={\n",
    "#         \"MAE\": torchmetrics.MeanAbsoluteError()\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def my_loss(input, target):\n",
    "#     classInput = input.int()\n",
    "#     pos_weight = torch.ones([64])\n",
    "#     criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "#     return criterion(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn.modules.loss import _Loss\n",
    "# from typing import Callable, Optional\n",
    "\n",
    "# class myBCEWithLogitsLoss(_Loss):\n",
    "\n",
    "#     def __init__(self, weight: Optional[torch.Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean',\n",
    "#                  pos_weight: Optional[torch.Tensor] = None) -> None:\n",
    "#         super(myBCEWithLogitsLoss, self).__init__(size_average, reduce, reduction)\n",
    "#         self.register_buffer('weight', weight)\n",
    "#         self.register_buffer('pos_weight', pos_weight)\n",
    "#         self.weight: Optional[torch.Tensor]\n",
    "#         self.pos_weight: Optional[torch.Tensor]\n",
    "\n",
    "#     def forward(self, input, target):\n",
    "#         # target2=target.int()\n",
    "#         # return F.binary_cross_entropy_with_logits(input, target2,\n",
    "#         return F.binary_cross_entropy_with_logits(input, target,\n",
    "#                                                   self.weight,\n",
    "#                                                   pos_weight=self.pos_weight,\n",
    "#                                                   reduction=self.reduction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_synth = spk.task.ModelOutput(\n",
    "    name='synth',\n",
    "    # loss_fn=myBCEWithLogitsLoss(), \n",
    "    # loss_fn=torch.nn.BCEWithLogitsLoss(), \n",
    "    # loss_fn=torch.nn.CrossEntropyLoss(), \n",
    "    loss_fn=torch.nn.BCELoss(), \n",
    "    loss_weight=1.,\n",
    "    metrics={\n",
    "        \"Accur\": torchmetrics.Accuracy()   #potential alternatives: AUROC(increases the area under ROC curve), AveragePrecision (summarises the precision-recall curve)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmpi3xi8nq1\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmpi3xi8nq1/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "task = spk.task.AtomisticTask(\n",
    "    model=nnpot,\n",
    "    # outputs=[output_fepa],\n",
    "    outputs=[output_synth],\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    optimizer_args={\"lr\": 1e-4}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = pl.loggers.TensorBoardLogger(save_dir=qm9tut)\n",
    "callbacks = [\n",
    "    spk.train.ModelCheckpoint(\n",
    "        inference_path=os.path.join(qm9tut, \"best_inference_model\"),\n",
    "        save_top_k=1,\n",
    "        monitor=\"val_loss\"\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/samariam/anaconda3/envs/schDev/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1814: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=4)`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer = pl.Trainer(\n",
    "    # devices=2,   #error says a strategy is selected which is not compatible with interactive mode; regardless of choosing a \"compatible\" strategy.\n",
    "    # auto_select_gpus = False,\n",
    "    # gpus=[0],  #this selects the number of gpus to use, not the exact one.\n",
    "    # auto_select_gpus = True,\n",
    "    # gpus=1,  #this selects the number of gpus to use, not the exact one.\n",
    "    accelerator='cpu',\n",
    "    strategy=None,\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    default_root_dir=qm9tut,\n",
    "    max_epochs=3, # for testing, we restrict the number of epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need sigmoid before cross_entropy loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:09<00:00,  2.61it/s]\n",
      "\n",
      "  | Name    | Type                   | Params\n",
      "---------------------------------------------------\n",
      "0 | model   | NeuralNetworkPotential | 34.4 K\n",
      "1 | outputs | ModuleList             | 0     \n",
      "---------------------------------------------------\n",
      "34.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.4 K    Total params\n",
      "0.138     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b0c33636694789bbe13c275c551412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samariam/anaconda3/envs/schDev/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 18 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Double",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/samariam/projects/chemheuristics/schnetDevPUsingle.ipynb Cell 65\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsv2112/home/samariam/projects/chemheuristics/schnetDevPUsingle.ipynb#Y135sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# trainer.fit(task, train_dataloaders=train_loader, val_dataloaders=val_loader)#, datamodule=qm9data)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsv2112/home/samariam/projects/chemheuristics/schnetDevPUsingle.ipynb#Y135sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(task, datamodule\u001b[39m=\u001b[39;49mcrysData)\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:770\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[39mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 770\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    771\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    772\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:723\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    722\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 723\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    724\u001b[0m \u001b[39m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:811\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    807\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    808\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    809\u001b[0m     ckpt_path, model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    810\u001b[0m )\n\u001b[0;32m--> 811\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    813\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    814\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1236\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1234\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[0;32m-> 1236\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m   1238\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1239\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1323\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1321\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   1322\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1323\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1345\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_training_routine()\n\u001b[1;32m   1344\u001b[0m \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1345\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[1;32m   1347\u001b[0m \u001b[39m# enable train mode\u001b[39;00m\n\u001b[1;32m   1348\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1413\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1411\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[1;32m   1412\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m-> 1413\u001b[0m     val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1415\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1417\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 204\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    205\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:155\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_dataloaders \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    154\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mdataloader_idx\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dataloader_idx\n\u001b[0;32m--> 155\u001b[0m dl_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher, dl_max_batches, kwargs)\n\u001b[1;32m    157\u001b[0m \u001b[39m# store batch level output per dataloader\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs\u001b[39m.\u001b[39mappend(dl_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 204\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    205\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:128\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[0;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[1;32m    127\u001b[0m \u001b[39m# lightning module methods\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_step(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    129\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_step_end(output)\n\u001b[1;32m    131\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:226\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39m_call_strategy_hook(\u001b[39m\"\u001b[39m\u001b[39mtest_step\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39mkwargs\u001b[39m.\u001b[39mvalues())\n\u001b[1;32m    225\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 226\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_strategy_hook(\u001b[39m\"\u001b[39;49m\u001b[39mvalidation_step\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m    228\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1765\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1762\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1764\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1765\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1767\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1768\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py:344\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39m\"\"\"The actual validation step.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \n\u001b[1;32m    341\u001b[0m \u001b[39mSee :meth:`~pytorch_lightning.core.lightning.LightningModule.validation_step` for more details\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mval_step_context():\n\u001b[0;32m--> 344\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mvalidation_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/schnetpack/task.py:199\u001b[0m, in \u001b[0;36mAtomisticTask.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_without_postprocessing(batch)\n\u001b[1;32m    200\u001b[0m pred, targets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_constraints(pred, targets)\n\u001b[1;32m    202\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fn(pred, targets)\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/schnetpack/task.py:234\u001b[0m, in \u001b[0;36mAtomisticTask.predict_without_postprocessing\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    232\u001b[0m pp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mdo_postprocessing\n\u001b[1;32m    233\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mdo_postprocessing \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(batch)\n\u001b[1;32m    235\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mdo_postprocessing \u001b[39m=\u001b[39m pp\n\u001b[1;32m    236\u001b[0m \u001b[39mreturn\u001b[39;00m pred\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/schnetpack/task.py:139\u001b[0m, in \u001b[0;36mAtomisticTask.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs: Dict[\u001b[39mstr\u001b[39m, torch\u001b[39m.\u001b[39mTensor]):\n\u001b[0;32m--> 139\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(inputs)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/schnetpack/model/base.py:174\u001b[0m, in \u001b[0;36mNeuralNetworkPotential.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_modules:\n\u001b[1;32m    172\u001b[0m     inputs \u001b[39m=\u001b[39m m(inputs)\n\u001b[0;32m--> 174\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepresentation(inputs)\n\u001b[1;32m    176\u001b[0m \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_modules:\n\u001b[1;32m    177\u001b[0m     inputs \u001b[39m=\u001b[39m m(inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/schnetpack/representation/schnet.py:152\u001b[0m, in \u001b[0;36mSchNet.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39m# compute interaction block to update atomic embeddings\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39mfor\u001b[39;00m interaction \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minteractions:\n\u001b[0;32m--> 152\u001b[0m     v \u001b[39m=\u001b[39m interaction(x, f_ij, idx_i, idx_j, rcut_ij)\n\u001b[1;32m    153\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m v\n\u001b[1;32m    155\u001b[0m inputs[\u001b[39m\"\u001b[39m\u001b[39mscalar_representation\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m x\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/schnetpack/representation/schnet.py:62\u001b[0m, in \u001b[0;36mSchNetInteraction.forward\u001b[0;34m(self, x, f_ij, idx_i, idx_j, rcut_ij)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m\"\"\"Compute interaction output.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39m    atom features after interaction\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min2f(x)\n\u001b[0;32m---> 62\u001b[0m Wij \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilter_network(f_ij)\n\u001b[1;32m     63\u001b[0m Wij \u001b[39m=\u001b[39m Wij \u001b[39m*\u001b[39m rcut_ij[:, \u001b[39mNone\u001b[39;00m]\n\u001b[1;32m     65\u001b[0m \u001b[39m# continuous-filter convolution\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/schnetpack/nn/base.py:53\u001b[0m, in \u001b[0;36mDense.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m---> 53\u001b[0m     y \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n\u001b[1;32m     54\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(y)\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m y\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Double"
     ]
    }
   ],
   "source": [
    "# trainer.fit(task, train_dataloaders=train_loader, val_dataloaders=val_loader)#, datamodule=qm9data)\n",
    "trainer.fit(task, datamodule=crysData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_idx': tensor([0]),\n",
       " 'synth': tensor([0.]),\n",
       " '_n_atoms': tensor([10]),\n",
       " '_atomic_numbers': tensor([57, 57, 22, 30,  8,  8,  8,  8,  8,  8]),\n",
       " '_positions': tensor([[ 9.5927e+00,  1.2888e-16,  3.4652e+00],\n",
       "         [ 3.1952e+00, -5.0175e-17,  1.1542e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 6.3940e+00,  0.0000e+00,  2.3097e+00],\n",
       "         [ 5.7309e+00, -1.2531e+00,  7.4232e-01],\n",
       "         [ 5.4632e+00,  1.7081e+00,  1.4835e+00],\n",
       "         [ 4.7258e+00, -4.5499e-01,  3.5249e+00],\n",
       "         [ 7.0570e+00,  1.2531e+00,  3.8770e+00],\n",
       "         [ 8.0621e+00,  4.5499e-01,  1.0945e+00],\n",
       "         [ 7.3247e+00, -1.7081e+00,  3.1359e+00]], dtype=torch.float64),\n",
       " '_cell': tensor([[[ 4.8189, -2.8357,  0.0000],\n",
       "          [ 4.8189,  2.8357,  0.0000],\n",
       "          [ 3.1502,  0.0000,  4.6194]]], dtype=torch.float64),\n",
       " '_pbc': tensor([True, True, True])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        dtype\n",
      "\u001b[0;31mString form:\u001b[0m torch.int32\n",
      "\u001b[0;31mFile:\u001b[0m        ~/anaconda3/envs/schDev/lib/python3.9/site-packages/torch/__init__.py\n",
      "\u001b[0;31mDocstring:\u001b[0m   <no docstring>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = torch.load(os.path.join(qm9tut, 'best_inference_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samariam/anaconda3/envs/schDev/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 18 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771fe44ed2b246abafc33c2c2b507952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samariam/anaconda3/envs/schDev/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 4. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    192.18838500976562     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_synth_MAE       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    13.643445014953613     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   192.18838500976562    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_synth_MAE      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   13.643445014953613    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 192.18838500976562, 'test_synth_MAE': 13.643445014953613}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(task, crysData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training on class labels: [{'test_loss': 2.7045037746429443, 'test_synth_MAE': 1.297343373298645}]\n",
    "It seems like the test_loss magnitude is changes more with the target?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after 3 epochs: [{'test_loss': 11.951684951782227, 'test_fepa_MAE': 2.681666851043701}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after 10 epochs: [{'test_loss': 2.2840123176574707, 'test_fepa_MAE': 1.183426022529602}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3319058519.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [54]\u001b[0;36m\u001b[0m\n\u001b[0;31m    stop!\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.predict(task, crysData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reload_ext tensorboard\n",
    "# %tensorboard --logdir=./qm9tut/lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3319058519.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [50]\u001b[0;36m\u001b[0m\n\u001b[0;31m    stop!\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crysData.setup()  #does not seem to make a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,batch in enumerate(crysData.test_dataloader()):\n",
    "#     print('starting {}'.format(i)) \n",
    "#     result = best_model(batch)\n",
    "#     err = sum(abs(batch['fepa'].detach().numpy()-result['fepa'].detach().numpy()))\n",
    "#     print('The absolute error is',err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing with data not already seen by the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = spk.interfaces.AtomsConverter(neighbor_list=trn.ASENeighborList(cutoff=5.), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = best_model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testCrysdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>myatoms</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>(Atom('Ba', [6.3479265, 6.3479265, 6.3479265],...</td>\n",
       "      <td>{'synth': [1]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>(Atom('Sr', [-6.554058096241989e-18, 6.5540580...</td>\n",
       "      <td>{'synth': [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>(Atom('Cr', [2.9588875, 1.955123, 6.3714835], ...</td>\n",
       "      <td>{'synth': [1]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>(Atom('Cs', [0.012741762408, 0.0, 3.3283214304...</td>\n",
       "      <td>{'synth': [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>(Atom('Co', [2.854327, 2.876323999999999, 4.22...</td>\n",
       "      <td>{'synth': [0]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               myatoms         targets\n",
       "115  (Atom('Ba', [6.3479265, 6.3479265, 6.3479265],...  {'synth': [1]}\n",
       "116  (Atom('Sr', [-6.554058096241989e-18, 6.5540580...  {'synth': [0]}\n",
       "117  (Atom('Cr', [2.9588875, 1.955123, 6.3714835], ...  {'synth': [1]}\n",
       "118  (Atom('Cs', [0.012741762408, 0.0, 3.3283214304...  {'synth': [0]}\n",
       "119  (Atom('Co', [2.854327, 2.876323999999999, 4.22...  {'synth': [0]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testCrysdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_test(x):\n",
    "    inputs = converter(x)\n",
    "    pred = best_model(inputs)\n",
    "    pred_arr = next(iter(pred.values())).detach().numpy()    #dict_value to array\n",
    "    if (1-pred_arr<pred_arr):\n",
    "        pred_arr = 1\n",
    "    else:\n",
    "        pred_arr = 0\n",
    "    return pred_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predSynth = []\n",
    "    \n",
    "for ind, row in testCrysdf.iterrows():\n",
    "    # print(ind) \n",
    "    # print(row)\n",
    "    inputs = converter(row['myatoms'])\n",
    "    pred = best_model(inputs)\n",
    "    pred_arr = next(iter(pred.values())).detach().numpy()    #dict_value to array\n",
    "    # print(pred_arr)\n",
    "    if (1-pred_arr<pred_arr):\n",
    "        pred_arr = 1\n",
    "    else:\n",
    "        pred_arr = 0\n",
    "    predSynth.append([ind,pred_arr])\n",
    "    \n",
    "    \n",
    "# for datum in predSynth:     #changing the reg output to class labels based on distance from label value\n",
    "#     if (1-datum[1]<datum[1]):\n",
    "#         datum[1] = 1\n",
    "#     else:\n",
    "#         datum[1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_col = pd.Series(data=[datum[1] for datum in predSynth], index=[datum[0] for datum in predSynth])\n",
    "pred_col = pd.DataFrame(data=[datum[1] for datum in predSynth], \n",
    "            index=[datum[0] for datum in predSynth], columns=['test'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCrysdf['mycol'] = testCrysdf.myatoms.apply(lambda x: pred_test(x))\n",
    "# df1 = df.apply(lambda x: x * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>myatoms</th>\n",
       "      <th>targets</th>\n",
       "      <th>0</th>\n",
       "      <th>mycol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Atom('O', [0.0, 0.0, 1.94282375], magmom=-0.0...</td>\n",
       "      <td>{'synth': [0]}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Atom('W', [1.554401, -0.8974354615340001, 8.2...</td>\n",
       "      <td>{'synth': [0]}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Atom('La', [9.59190380106, -7.207891786720211...</td>\n",
       "      <td>{'synth': [0]}</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Atom('Yb', [0.0, 0.0, 0.0], magmom=0.018, ind...</td>\n",
       "      <td>{'synth': [0]}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Atom('Cr', [-2.7845342297320004, 2.5697284645...</td>\n",
       "      <td>{'synth': [0]}</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>(Atom('Ba', [6.3479265, 6.3479265, 6.3479265],...</td>\n",
       "      <td>{'synth': [1]}</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>(Atom('Sr', [-6.554058096241989e-18, 6.5540580...</td>\n",
       "      <td>{'synth': [0]}</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>(Atom('Cr', [2.9588875, 1.955123, 6.3714835], ...</td>\n",
       "      <td>{'synth': [1]}</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>(Atom('Cs', [0.012741762408, 0.0, 3.3283214304...</td>\n",
       "      <td>{'synth': [0]}</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>(Atom('Co', [2.854327, 2.876323999999999, 4.22...</td>\n",
       "      <td>{'synth': [0]}</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               myatoms         targets  0  \\\n",
       "0    (Atom('O', [0.0, 0.0, 1.94282375], magmom=-0.0...  {'synth': [0]}  0   \n",
       "1    (Atom('W', [1.554401, -0.8974354615340001, 8.2...  {'synth': [0]}  0   \n",
       "2    (Atom('La', [9.59190380106, -7.207891786720211...  {'synth': [0]}  1   \n",
       "3    (Atom('Yb', [0.0, 0.0, 0.0], magmom=0.018, ind...  {'synth': [0]}  0   \n",
       "4    (Atom('Cr', [-2.7845342297320004, 2.5697284645...  {'synth': [0]}  1   \n",
       "..                                                 ...             ... ..   \n",
       "115  (Atom('Ba', [6.3479265, 6.3479265, 6.3479265],...  {'synth': [1]}  1   \n",
       "116  (Atom('Sr', [-6.554058096241989e-18, 6.5540580...  {'synth': [0]}  1   \n",
       "117  (Atom('Cr', [2.9588875, 1.955123, 6.3714835], ...  {'synth': [1]}  1   \n",
       "118  (Atom('Cs', [0.012741762408, 0.0, 3.3283214304...  {'synth': [0]}  1   \n",
       "119  (Atom('Co', [2.854327, 2.876323999999999, 4.22...  {'synth': [0]}  1   \n",
       "\n",
       "     mycol  \n",
       "0        0  \n",
       "1        0  \n",
       "2        1  \n",
       "3        0  \n",
       "4        1  \n",
       "..     ...  \n",
       "115      1  \n",
       "116      1  \n",
       "117      1  \n",
       "118      1  \n",
       "119      1  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testCrysdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_it = 5\n",
    "testCrysdf = testCrysdf.merge(pred_col, left_index=True, right_index=True, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>myatoms</th>\n",
       "      <th>targets</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Atom('O', [0.0, 0.0, 1.94282375], magmom=-0.0...</td>\n",
       "      <td>{'synth': [0]}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Atom('W', [1.554401, -0.8974354615340001, 8.2...</td>\n",
       "      <td>{'synth': [0]}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Atom('La', [9.59190380106, -7.207891786720211...</td>\n",
       "      <td>{'synth': [0]}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Atom('Yb', [0.0, 0.0, 0.0], magmom=0.018, ind...</td>\n",
       "      <td>{'synth': [0]}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Atom('Cr', [-2.7845342297320004, 2.5697284645...</td>\n",
       "      <td>{'synth': [0]}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             myatoms         targets  0\n",
       "0  (Atom('O', [0.0, 0.0, 1.94282375], magmom=-0.0...  {'synth': [0]}  0\n",
       "1  (Atom('W', [1.554401, -0.8974354615340001, 8.2...  {'synth': [0]}  0\n",
       "2  (Atom('La', [9.59190380106, -7.207891786720211...  {'synth': [0]}  1\n",
       "3  (Atom('Yb', [0.0, 0.0, 0.0], magmom=0.018, ind...  {'synth': [0]}  0\n",
       "4  (Atom('Cr', [-2.7845342297320004, 2.5697284645...  {'synth': [0]}  1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cur_it = 5\n",
    "testCrysdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to check a data point or accuracy:\n",
    "acc = []\n",
    "for d in predSynth:\n",
    "    acc.append(next(iter(testCrysdf.iloc[d[0]].targets.values()))==d[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36666667])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(acc)/len(acc) #this doesn't mean much because we don't know about unlabele data.\n",
    "# we want to group the positive label data points together anc check the rate of true positives there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [datum['fepa'].detach().numpy() for datum in predFepa]\n",
    "fepaTestVals = [datum['fepa'] for datum in fepaTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(fepaTestVals, res)\n",
    "plt.xlabel(\"Target values\");\n",
    "plt.ylabel(\"Predictions\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are different test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.146852985290763"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(fepaTestVals, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2532482934916755"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_absolute_error(fepaTestVals, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.906101673587742"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(fepaTestVals, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.34585335907423"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_squared_error(fepaTestVals, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crysData.test_dataloader().pin_memory_device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code we might use later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MetricTracker(pl.callbacks.Callback):\n",
    "#     def __init__(self):\n",
    "#         self.val_error_batch   = []\n",
    "#         self.val_error         = []\n",
    "#         self.train_error_batch = []\n",
    "#         self.train_error       = []\n",
    "\n",
    "#     def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
    "#         self.train_error_batch.append(outputs['loss'].item())\n",
    "\n",
    "#     def on_train_epoch_end(self, *args, **kwargs):\n",
    "#         self.train_error.append(np.mean(self.train_error_batch))\n",
    "#         self.train_error_batch = []\n",
    "\n",
    "#     def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx):\n",
    "#         self.val_error_batch.append(outputs['val_loss'].item())\n",
    "\n",
    "#     def on_validation_epoch_end(self, trainer, pl_module):\n",
    "#         self.val_error.append(np.mean(self.val_error_batch))\n",
    "#         self.val_error_batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy_synth = pd.get_dummies(crysdf['targets'],prefix = 'synth')\n",
    "# crysdf = pd.merge(crysdf,dummy_synth,\n",
    "#     left_index=True,\n",
    "#     right_index=True,\n",
    "# )\n",
    "# crysdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# td = [batch for batch in crysData.test_dataloader()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the log file is not saved, at least where it was before. Have a look around, perhaps clean the folder\n",
    "# # or try in a different TEST folder and try again.\n",
    "# import matplotlib.pyplot as plt\n",
    "# from ase.units import kcal, mol\n",
    "\n",
    "# results = np.loadtxt(os.path.join(qm9tut, 'log.csv'), skiprows=1, delimiter=',')\n",
    "\n",
    "# time = results[:,0]-results[0,0]\n",
    "# learning_rate = results[:,1]\n",
    "# train_loss = results[:,2]\n",
    "# val_loss = results[:,3]\n",
    "# val_mae = results[:,4]\n",
    "\n",
    "# print('Final validation MAE:', np.round(val_mae[-1], 2), 'eV =',\n",
    "#       np.round(val_mae[-1] / (kcal/mol), 2), 'kcal/mol')\n",
    "\n",
    "# plt.figure(figsize=(14,5))\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.plot(time, val_loss, label='Validation')\n",
    "# plt.plot(time, train_loss, label='Train')\n",
    "# plt.yscale('log')\n",
    "# plt.ylabel('Loss [eV]')\n",
    "# plt.xlabel('Time [s]')\n",
    "# plt.legend()\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.plot(time, val_mae)\n",
    "# plt.ylabel('mean abs. error [eV]')\n",
    "# plt.xlabel('Time [s]')\n",
    "# # plt.show()\n",
    "# # plt.savefig('tempfigDev.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('schDev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ec8daa6277410c566eb6b054d9eca152cf5f39aaee5ee7a397951c4f9bce03d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
