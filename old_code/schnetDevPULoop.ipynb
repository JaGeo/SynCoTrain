{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set up for using Schnet on our crystal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 18 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path  #recommended path library for python3\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import schnetpack as spk\n",
    "from schnetpack.data import ASEAtomsData, BaseAtomsData, AtomsDataFormat, AtomsDataModule\n",
    "import schnetpack.transform as trn\n",
    "import torch\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/samariam/projects/chemheuristics\n",
      "/home/samariam/projects/chemheuristics\n"
     ]
    }
   ],
   "source": [
    "print(Path().resolve())  #current working directory\n",
    "print(Path().absolute()) #file path in jupyter\n",
    "# print(Path(__file__).parent.resolve()) #file path (dcript directory) path in a python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def directory_setup(dataPath,save_dir, bestModelPath, iteration_num=None):\n",
    "    if iteration_num == 0:\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "            print('Logging directory was created')\n",
    "        \n",
    "    splitFile_path = Path('split.npz')\n",
    "    try:\n",
    "        splitFile_path.unlink()\n",
    "    except OSError as e:\n",
    "        print(e)\n",
    "        splitFile_path = Path(save_dir+'/'+str(splitFile_path))\n",
    "        try:\n",
    "            splitFile_path.unlink()\n",
    "        except OSError as e:\n",
    "            print(e)\n",
    "            \n",
    "    datapathObj = Path(dataPath)\n",
    "    try:\n",
    "        datapathObj.unlink()\n",
    "    except OSError as e:\n",
    "        print(e)        \n",
    "        \n",
    "    bestModelPath_obj = Path(bestModelPath)\n",
    "    try:\n",
    "        bestModelPath_obj.unlink()\n",
    "    except OSError as e:\n",
    "        print(e)       \n",
    "         \n",
    "    return str(splitFile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_test(x, best_model):\n",
    "    inputs = converter(x)\n",
    "    pred = best_model(inputs)\n",
    "    pred_arr = next(iter(pred.values())).detach().numpy()    #dict_value to array\n",
    "    if (1-pred_arr<pred_arr):\n",
    "        pred_arr = 1\n",
    "    else:\n",
    "        pred_arr = 0\n",
    "    return pred_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Important note!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm gonna use electron volt for the compulsory unit decleration to see if I can complete the classification workflow. But even if it works I'll need to fix it soon. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'll try doing a regression and getting the round number (or closest number to label) as the class. Later I'll have to use classiification loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "torch.device('cpu')     #gpu was busy\n",
    "# print(torch.tensor([1., 2.]).device)      #checking the current device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "pAtoms = np.load(\"data_for_dev_try/PosAtomsUnder12.npy\", allow_pickle=True)\n",
    "tAtoms = np.load(\"data_for_dev_try/TheoAtomsUnder12.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pSynth = [np.array(1).flatten()]*len(pAtoms)    #we need the array to have the shape (1,), hence we use flatten()\n",
    "tSynth = [np.array(0).flatten()]*len(tAtoms)\n",
    "crysData = np.concatenate([pAtoms, tAtoms])\n",
    "targetData = [*pSynth, *tSynth]   #again, we need distinct arrays. np.concatenate would merge all in one array.\n",
    "crysdf = pd.DataFrame()\n",
    "crysdf['myatoms'] = crysData\n",
    "crysdf['target_pd'] = targetData\n",
    "if targetData[0].shape !=(1,):\n",
    "    print(\"Target data has the wrong shape of \", targetData[0].shape)\n",
    "    # break\n",
    "crysdf[\"targets\"] = crysdf.target_pd.map(lambda crystalClass: dict(synth=np.array(crystalClass)) )     #changes targets fromat from array to dict with array val\n",
    "crysdf = crysdf.reset_index(drop=False)\n",
    "crysdf = crysdf.rename(columns={'index':'crystal_id'})\n",
    "crysdf = crysdf.sample(frac=1, random_state=42).reset_index(drop=True)     #simply shuffles the rows of positive and Unlabeled(negative) data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmpeekfq5p_\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmpeekfq5p_/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "cutoff = 5\n",
    "radial_basis = spk.nn.GaussianRBF(n_rbf=20, cutoff=cutoff)\n",
    "n_atom_basis = 30\n",
    "n_filters = 64\n",
    "dataPath = './class_dataset.db'\n",
    "save_dir = './qm9tut'\n",
    "bestModelPath = save_dir+'/'+'best_inference_model'\n",
    "pairwise_distance = spk.atomistic.PairwiseDistances() # calculates pairwise distances between atoms\n",
    "\n",
    "schnet = spk.representation.SchNet(\n",
    "    n_atom_basis=n_atom_basis, n_filters=n_filters, n_interactions=3, radial_basis=radial_basis,    \n",
    "    cutoff_fn = spk.nn.CosineCutoff(cutoff),\n",
    ")\n",
    "\n",
    "pred_synth = spk.atomistic.Atomwise(n_in=n_atom_basis, output_key='synth')\n",
    "\n",
    "nnpot = spk.model.NeuralNetworkPotential(\n",
    "    representation=schnet,\n",
    "    input_modules=[pairwise_distance],\n",
    "    output_modules=[pred_synth],\n",
    "    postprocessors=[trn.CastTo64(), trn.AddOffsets('synth', add_mean=True, add_atomrefs=False)]  \n",
    ")\n",
    "\n",
    "output_synth = spk.task.ModelOutput(\n",
    "    name='synth',\n",
    "    loss_fn=torch.nn.MSELoss(), #this+metrics below later changes to BCELoss \n",
    "    loss_weight=1.,\n",
    "    metrics={\n",
    "        \"MAE\": torchmetrics.MeanAbsoluteError()\n",
    "    }\n",
    ")\n",
    "\n",
    "task = spk.task.AtomisticTask(\n",
    "    model=nnpot,\n",
    "    outputs=[output_synth],\n",
    "    optimizer_cls=torch.optim.AdamW,\n",
    "    optimizer_args={\"lr\": 1e-4}\n",
    ")\n",
    "\n",
    "max_epochs = 13\n",
    "\n",
    "converter = spk.interfaces.AtomsConverter(neighbor_list=trn.ASENeighborList(cutoff=5.), dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we started iteration 0\n",
      "[Errno 2] No such file or directory: 'split.npz'\n",
      "[Errno 2] No such file or directory: 'qm9tut/best_inference_model'\n",
      "The #training data is 2711, #validation data 675 and #internal test data 6. \n",
      "adding systems to dataset\n",
      "creating data module\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:06<00:00, 22.62it/s]\n",
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/samariam/anaconda3/envs/schDev/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1814: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=4)`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean atomization energy / atom: 0.045434826044403534\n",
      "Std. dev. atomization energy / atom: 0.08243758530750642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:06<00:00, 22.54it/s]\n",
      "\n",
      "  | Name    | Type                   | Params\n",
      "---------------------------------------------------\n",
      "0 | model   | NeuralNetworkPotential | 34.4 K\n",
      "1 | outputs | ModuleList             | 0     \n",
      "---------------------------------------------------\n",
      "34.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.4 K    Total params\n",
      "0.138     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22116f30c1924c6d90b3f2be757e445d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samariam/anaconda3/envs/schDev/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 20. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436d965c26bb4f5d8e0d16660aec03e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samariam/anaconda3/envs/schDev/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 11. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4b008a07624a679e190e6738b790c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samariam/anaconda3/envs/schDev/lib/python3.9/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 15. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e30a3058011a403b966339dc810fcca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ed62c513e2495bab924c03c55057a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610fe8ddb69d40528022dc3009df45a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samariam/anaconda3/envs/schDev/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:726: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===the 0th iteration took 0:02:06.432952 to run===\n"
     ]
    }
   ],
   "source": [
    "num_iter = 1\n",
    "#  ###for the gpu I forgot to change pin_memory to True in AtomsDataModule.\n",
    "# ###figure out time from Tensorboard\n",
    "# ###if we sample without replacement, it'll be a wider search, but less robust for each datum.\n",
    "for it in range(num_iter):\n",
    "    st = time.time()\n",
    "    print('we started iteration {}'.format(it))\n",
    "    splitFilestring = directory_setup(dataPath = dataPath,save_dir = save_dir, bestModelPath= bestModelPath, iteration_num=it)\n",
    "    \n",
    "    np.random.seed(it)\n",
    "    crysdf = crysdf.sample(frac=1, random_state=it).reset_index(drop=True)     #simply shuffles the rows of positive and Unlabeled(negative) data\n",
    "    # this first shuffling is useless\n",
    "    num_pos = crysdf.target_pd.sum()\n",
    "    num_theo = crysdf.shape[0]-num_pos\n",
    "    \n",
    "    pos_train_num = int(0.9*num_pos)\n",
    "    theo_train_num = int(0.85*num_theo)   #this should change to have the same size of P and U samples in each iter.\n",
    "    \n",
    "    df0 = crysdf[crysdf.target_pd==0].sample(n=theo_train_num,random_state=it)\n",
    "    df1 = crysdf[crysdf.target_pd==1].sample(n=pos_train_num,random_state=it+1)\n",
    "    \n",
    "    it_train_df = pd.concat([df0,df1]).reset_index(drop=True)\n",
    "    it_train_df = it_train_df.sample(frac=1,random_state=it+2)\n",
    "    \n",
    "    theoTestDf = crysdf[crysdf.target_pd==0].drop(index=df0.index)    #how to mask for selecting theoretical data\n",
    "    posTestDf = crysdf[crysdf.target_pd==1].drop(index=df1.index)    #how to mask for selecting positive data\n",
    "    # maybe we could concat the indexes and drop only once. Doesn't matter.\n",
    "    \n",
    "    it_test_df = pd.concat([theoTestDf,posTestDf])\n",
    "    it_test_df = it_test_df.sample(frac=1,random_state=it+2).reset_index(drop=True)\n",
    "    \n",
    "    trainLength = round(len(it_train_df)*.8)-3\n",
    "    valLength = round(len(it_train_df)*.2)-3\n",
    "    innerTestLength = len(it_train_df)-(trainLength+valLength)   #We do our own testing manually later on.\n",
    "\n",
    "    if it==0:\n",
    "        print('The #training data is {}, #validation data {} and #internal test data {}. '.format(trainLength, valLength, innerTestLength))\n",
    "        \n",
    "\n",
    "    class_dataset = ASEAtomsData.create(dataPath, \n",
    "                                    distance_unit='Ang',\n",
    "                                    property_unit_dict={'synth':'eV'}     #We need to do something about this unit.                             \n",
    "                                     )\n",
    "    print('adding systems to dataset')\n",
    "    class_dataset.add_systems(np.array(crysdf.targets), np.array(crysdf.myatoms))  \n",
    "    \n",
    "    print('creating data module')\n",
    "    crysData = AtomsDataModule(datapath=dataPath,\n",
    "                   batch_size=20,\n",
    "                    num_train=trainLength,\n",
    "                    num_val=valLength,\n",
    "                    transforms=[\n",
    "                        trn.ASENeighborList(cutoff=5.),\n",
    "                        trn.CastTo32(), \n",
    "                        # trn.RemoveOffsets('fepa', remove_mean=True, remove_atomrefs=True),\n",
    "                                ],\n",
    "                    property_units={'synth':'eV'},\n",
    "                    num_workers=10,    #we started with 1\n",
    "                    split_file = splitFilestring, \n",
    "                    pin_memory=False, # set to false, when not using a GPU\n",
    "                    # pin_memory=True, # set to false, when not using a GPU\n",
    "                    load_properties=['synth'], #only load U0 property\n",
    "    )\n",
    "    \n",
    "    crysData.prepare_data()\n",
    "    crysData.setup()\n",
    "    \n",
    "    means, stddevs = crysData.get_stats(\n",
    "    'synth', divide_by_atoms=True, remove_atomref=True)\n",
    "    \n",
    "    print('Mean atomization energy / atom:', means.item())\n",
    "    print('Std. dev. atomization energy / atom:', stddevs.item())\n",
    "    # This doesn't work when no test data is given, and it has no docstring. Does it calculate the mean and and std of test data?\n",
    "    \n",
    "    logger = pl.loggers.TensorBoardLogger(save_dir=save_dir)\n",
    "    callbacks = [\n",
    "    spk.train.ModelCheckpoint(\n",
    "        inference_path=os.path.join(save_dir, \"best_inference_model\"),\n",
    "        save_top_k=1,\n",
    "        monitor=\"val_loss\"\n",
    "    )\n",
    "    ]\n",
    "    \n",
    "    trainer = pl.Trainer(#accelerator='gpu', devices=4,\n",
    "    accelerator='cpu',\n",
    "    # gpus=[0,1],\n",
    "    # auto_select_gpus = True,\n",
    "    strategy=None,\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    default_root_dir=save_dir,\n",
    "    max_epochs=max_epochs, # for testing, we restrict the number of epochs\n",
    ")\n",
    "    trainer.fit(task, datamodule=crysData)\n",
    "    best_model = torch.load(bestModelPath)\n",
    "    best_model = best_model.to('cpu')\n",
    "    \n",
    "    it_test_df['pred_'+str(it)] = it_test_df.myatoms.apply(lambda x: pred_test(x, best_model=best_model))\n",
    "    \n",
    "    # t = it_test_df.sample(frac=1,random_state=it+2)#.set_index('crystal_id')\n",
    "    it_test_df = it_test_df[['crystal_id','pred_'+str(it)]]\n",
    "    \n",
    "    crysdf = pd.merge(left = crysdf, right=it_test_df,how = 'outer',left_on='crystal_id', right_on='crystal_id')\n",
    "    \n",
    "    et = time.time()\n",
    "    itt = et-st\n",
    "    print(\"===the {}th iteration took {} to run===\".format(it, timedelta(seconds=itt)))\n",
    "    # break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crysdf.target_pd = crysdf.target_pd.map(lambda x: int(x[0])) #changing array to target for easier handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crysdf.to_csv(save_dir+'/res_df/crysdf2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crystal_id</th>\n",
       "      <th>myatoms</th>\n",
       "      <th>target_pd</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>(Atom('Rb', [5.1578925, 5.1578925, 5.1578925],...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'synth': [1]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>267</td>\n",
       "      <td>(Atom('Eu', [2.041225, 2.041225, 2.041225], ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'synth': [1]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1044</td>\n",
       "      <td>(Atom('K', [0.0, 0.0, 3.604327], magmom=-0.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'synth': [1]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1947</td>\n",
       "      <td>(Atom('Fe', [0.0, 0.0, 0.0], magmom=3.999, ind...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'synth': [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>357</td>\n",
       "      <td>(Atom('Al', [0.0, 0.0, 0.0], magmom=-0.0, inde...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'synth': [1]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   crystal_id                                            myatoms  target_pd  \\\n",
       "0          29  (Atom('Rb', [5.1578925, 5.1578925, 5.1578925],...          1   \n",
       "1         267  (Atom('Eu', [2.041225, 2.041225, 2.041225], ma...          1   \n",
       "2        1044  (Atom('K', [0.0, 0.0, 3.604327], magmom=-0.0, ...          1   \n",
       "3        1947  (Atom('Fe', [0.0, 0.0, 0.0], magmom=3.999, ind...          0   \n",
       "4         357  (Atom('Al', [0.0, 0.0, 0.0], magmom=-0.0, inde...          1   \n",
       "\n",
       "          targets  \n",
       "0  {'synth': [1]}  \n",
       "1  {'synth': [1]}  \n",
       "2  {'synth': [1]}  \n",
       "3  {'synth': [0]}  \n",
       "4  {'synth': [1]}  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crysdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crysdf = pd.read_csv(save_dir+'/res_df/crysdf2.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Preds = crysdf.drop(columns=['crystal_id', 'myatoms', 'target_pd', 'targets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreFunc(x):\n",
    "    iter_num = sum(x.notna())\n",
    "    if iter_num == 0:\n",
    "        return np.nan, iter_num\n",
    "    res = x.sum()\n",
    "    score = res/iter_num\n",
    "    return score, iter_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (2) does not match length of index (3922)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/samariam/projects/chemheuristics/schnetDevPULoop.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsv2112/home/samariam/projects/chemheuristics/schnetDevPULoop.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m crysdf[\u001b[39m'\u001b[39m\u001b[39mPreds\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m Preds\u001b[39m.\u001b[39;49mapply(scoreFunc, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/pandas/core/frame.py:8845\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8834\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   8836\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   8837\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   8838\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8843\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   8844\u001b[0m )\n\u001b[0;32m-> 8845\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/pandas/core/apply.py:727\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[39m# one axis empty\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39mshape):\n\u001b[0;32m--> 727\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_empty_result()\n\u001b[1;32m    729\u001b[0m \u001b[39m# raw\u001b[39;00m\n\u001b[1;32m    730\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/pandas/core/apply.py:797\u001b[0m, in \u001b[0;36mFrameApply.apply_empty_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    795\u001b[0m         r \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan\n\u001b[0;32m--> 797\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_constructor_sliced(r, index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magg_axis)\n\u001b[1;32m    798\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    799\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/pandas/core/series.py:442\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    440\u001b[0m     index \u001b[39m=\u001b[39m default_index(\u001b[39mlen\u001b[39m(data))\n\u001b[1;32m    441\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n\u001b[0;32m--> 442\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(data, index)\n\u001b[1;32m    444\u001b[0m \u001b[39m# create/copy the manager\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, (SingleBlockManager, SingleArrayManager)):\n",
      "File \u001b[0;32m~/anaconda3/envs/schDev/lib/python3.9/site-packages/pandas/core/common.py:557\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m--> 557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    558\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    559\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    560\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    561\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    562\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (2) does not match length of index (3922)"
     ]
    }
   ],
   "source": [
    "crysdf['Preds'] = Preds.apply(scoreFunc, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crysdf[['Preds', 'iter_num']] = crysdf.Preds.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = crysdf[crysdf.Preds.notna()][['target_pd', 'Preds', 'iter_num']]  #selecting data with prediction values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_df = res_df[res_df.target_pd==1]\n",
    "# theoretical_df = res_df[res_df.target_pd==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive_rate = sum(experimental_df[experimental_df.target_pd==1].Preds>=.5)/experimental_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our true positive rate is 95.1% after 75 iterations of 13 epochs.\n"
     ]
    }
   ],
   "source": [
    "print('Our true positive rate is {:.1f}% after {} iterations of {} epochs.'.format(true_positive_rate*100, num_iter, max_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This script took 0:03:25.654077 to run.\n"
     ]
    }
   ],
   "source": [
    "endTime = time.time()\n",
    "elapsed_time = endTime-startTime\n",
    "print(\"This script took {} to run.\".format(timedelta(seconds=elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_pd</th>\n",
       "      <th>Preds</th>\n",
       "      <th>iter_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_pd     Preds  iter_num\n",
       "0          1  1.000000      15.0\n",
       "1          0  0.923077      13.0\n",
       "2          0  1.000000      14.0\n",
       "3          0  0.000000      12.0\n",
       "4          0  1.000000       6.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_pd     0.000000\n",
       "Preds         0.090909\n",
       "iter_num     22.000000\n",
       "Name: 3400, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.iloc[res_df.iter_num.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_pd</th>\n",
       "      <th>Preds</th>\n",
       "      <th>iter_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target_pd     Preds  iter_num\n",
       "0           1  1.000000      15.0\n",
       "11          1  1.000000       4.0\n",
       "12          1  1.000000       5.0\n",
       "14          1  0.666667       6.0\n",
       "16          1  1.000000       5.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimental_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_pd     1.0\n",
       "Preds         1.0\n",
       "iter_num     16.0\n",
       "Name: 1085, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimental_df.iloc[experimental_df.iter_num.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('schDev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ec8daa6277410c566eb6b054d9eca152cf5f39aaee5ee7a397951c4f9bce03d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
